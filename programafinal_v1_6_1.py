# -*- coding: utf-8 -*-
"""ProgramaFinal_v1_6_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J4gZ8FfH-YaFh3_SWrgaftz4XYNnWxAy

# Herramienta para detección precoz de enfermedades en base a secuencias de ARN no codificante v1.6.1

En ésta versión del programa completo, en su modo de google collabs, es una primera aproximación al producto final. Se da la posibilidad de cargar todos los datasets de las 10 enfermedades principales, como también del top10 general. Las funciones, siguen siendo las mismas:

1.   Iniciación de todas las librerías a usar.
2.   Carga del modelo (archivo .pkl)
3.  ">>el usuario introduce la secuencia misteriosa<<"
4. Se hace un dataset en base a esa secuencia, que en las columnas de la 2 a la 30 posee las diversas características de la secuencia.
5. Con la secuencia caracterizada, se hace la predicción, que dará 1 si está asociada a la enfermedad particular, o 0, si no lo está.
6. Fin.

# 1) Carga de las librerías a usar
"""

#Importo las librerías que voy a usar

#primero PANDAS y Numpy, panda, porque está especializada en el manejo y análisis de estructuras de datos, y numpy para cuestiones matemáticas
import pandas as pd
import numpy as np
import os

from sklearn.preprocessing import StandardScaler#Entiendo que es para que no se vaya mucho de mambo el tema del tamaño de los datos. Concretamente, la
#descripción de la librería dice "estándariza los datos eliminando la media y escalando los datos de forma que su varianza sea igual a 1. Este tipo de escalado
# suele denominarse frecuentemente "normalización" de los datos."

import joblib

"""# 2) Selección de opción"""

print("¡Bienvenido a RNApred v1.6.1!")

print("\n")

print("Por favor, seleccione una opción para continuar, ingresando el número correspondiente:")

print("\n")

print("0. Sospecha general")
print("\n")
print("1. Sospecha de Cáncer de Próstata")
print("\n")
print("2. Sospecha de Cáncer de Páncreas")
print("\n")
print("3. Sospecha de Cáncer de Estómago")
print("\n")
print("4. Sospecha de Cáncer de Pulmón")
print("\n")
print("5. Sospecha de Glioblastoma")
print("\n")
print("6. Sospecha de Glioma")
print("\n")
print("7. Sospecha de Enfermedad de Alzheimer")
print("\n")
print("8. Sospecha de Cáncer de Mama")
print("\n")
print("9. Sospecha de Cáncer de Colon")
print("\n")
print("10. Sospecha de Cáncer de Hígado")
print("\n")

opcion = input()

#Acá cargo el dataset en la variable correspondiente.

if opcion == '1':
  dataset=pd.read_csv('dataset_PRC.csv')

elif opcion == '2':
  dataset=pd.read_csv('dataset_PC.csv')

elif opcion == '3':
  dataset=pd.read_csv('dataset_SC.csv')

elif opcion == '4':
  dataset=pd.read_csv('dataset_LC.csv')

elif opcion == '5':
  dataset=pd.read_csv('dataset_GBC.csv')

elif opcion == '6':
  dataset=pd.read_csv('dataset_GMA.csv')

elif opcion == '7':
  dataset=pd.read_csv('dataset_AD.csv')

elif opcion == '8':
  dataset=pd.read_csv('dataset_BC_1.csv')

elif opcion == '9':
  dataset=pd.read_csv('dataset_CRC_1.csv')

elif opcion == '10':
  dataset=pd.read_csv('dataset_HCA_1.csv')

elif opcion == '0':
  dataset=pd.read_csv('dataset_Top10_general_balanceado_20k0sy20k1s.csv')

#acá entiendo que estoy cargando en la variable los datos

dataset=dataset.drop(columns=['Unnamed: 0'])

def reset_index(df):
    df = df.reset_index(drop=True)
    return df


dataset = reset_index(dataset)#acá reinicio el conteo, porque borré y me quedan "saltos" entre filas contiguas

# Delete rows where case numbers are zero
# This deletion is completed by "selecting" rows where case numbers are non zero
dataset = dataset.loc[dataset["FC"] != 0]
dataset.shape

# split dataset
X_fitter = dataset.iloc[:, 2:30]#Acá, está asignando a la variable "X" todas las filas de las columnas de la 0 a la 11, pero sin la 11

#Feature scaling

sc_X = StandardScaler()

X_fitter = sc_X.fit_transform(X_fitter)

"""# 2) Carga del modelo a emplear para la predicción"""

# Carga del modelo
if opcion=='0':
  modelo = joblib.load('PRC_RFC_v1_0_4_Top10.pkl')

else:
  modelo = joblib.load('PRC_RFC_v1_0_4.pkl')



print("Ingrese secuencia de ARN")

#ARN_sec = "UAACAGUCUCCAGUCACGGCC"

ARN_sec = input()

# Crea un diccionario con la secuencia de ARN
secuencia_arn = {"secuencia": ARN_sec}

dataset = pd.DataFrame(secuencia_arn, index=[0])

dataset["longitud sec"] = dataset["secuencia"].str.len()

# Calculamos la proporción de cada nucleótido
dataset["Prop A"] = dataset["secuencia"].str.count("A") / dataset["longitud sec"]
dataset["Prop C"] = dataset["secuencia"].str.count("C") / dataset["longitud sec"]
dataset["Prop G"] = dataset["secuencia"].str.count("G") / dataset["longitud sec"]
dataset["Prop U"] = dataset["secuencia"].str.count("U") / dataset["longitud sec"]

# Calculamos la frecuencia de aparición de cada nucleótido
dataset["FA"] = dataset["secuencia"].str.count("A")
dataset["FC"] = dataset["secuencia"].str.count("C")
dataset["FG"] = dataset["secuencia"].str.count("G")
dataset["FU"] = dataset["secuencia"].str.count("U")

from scipy.spatial import distance

dataset["DHP"] = None  # Inicializamos la nueva columna totalmente vacía

for i in range(len(dataset)):

  RNA = dataset["secuencia"][i]



  RNA3i=list(RNA[0:3])



  n=3

  distancia=0

  contador=0#cuenta la cantidad de "tríos" de nucleótidos que va comparando

  while n + 3 <= len(RNA):
  #for i in range (3, len(RNA)):
    m=n+3



    RNA_siguiente=list(RNA[n:m])

    n+=3 #hasta acá funciona bien el bucle while. Faltaría ver si calcula
        #bien las distancias de hamming ahora...3

    distancia += (distance.hamming(RNA3i, RNA_siguiente))#* len(RNA3i)


    contador +=1


  DHP = round((distancia / contador)*len(RNA3i),2)

  dataset["DHP"][i] =DHP

  #G/C ratio (GCr)

if dataset["FC"].iloc[0]!=0:
  dataset["GCr"] = round(dataset["FG"] / dataset["FC"],4)

else:
  dataset["GCr"]=0

#G+C content (GpC), p de "plus" "Yi plas zi"
dataset["GpC"] = round((dataset["FG"] + dataset["FC"])/dataset["longitud sec"],4)

def calcular_dinucleotidos(secuencia):
    """
    Calculates the frequency of each dinucleótido in a given RNA sequence.

    Args:
        secuencia (str): The RNA sequence to analyze.

    Returns:
        dict: A dictionary containing the frequencies of each dinucleótido.
              If a dinucleotide is not present in the sequence, its value will be 0.

    Raises:
        ValueError: If the input sequence is not a string.
    """

    if not isinstance(secuencia, str):
        raise ValueError("Input sequence must be a string.")

    dinucleotidos = {}
    for i in range(len(secuencia) - 1):
        dinucleotido = secuencia[i:i+2]
        dinucleotidos[dinucleotido] = dinucleotidos.get(dinucleotido, 0) + 1
    return dinucleotidos

def agregar_columnas_dinucleotidos(df):
    """
    Adds 16 columns to the DataFrame containing the proportions of each dinucleótido
    in the 'secuencia' column.

    Args:
        df (pd.DataFrame): The DataFrame with the 'secuencia' column.

    Returns:
        pd.DataFrame: The DataFrame with the new dinucleotide proportion columns.
    """

    for dinucleótido in ["AA", "AC", "AG", "AU", "CA", "CC", "CG", "CU",
                        "GA", "GC", "GG", "GU", "UA", "UC", "UG", "UU"]:
        # Calculate the frequency of the dinucleótido and handle potential absence
        frecuencia = df["secuencia"].apply(
            lambda seq: calcular_dinucleotidos(seq).get(dinucleótido, 0)
        )

        # Calculate the proportion and add the column
        df[dinucleótido + "%"] = frecuencia / df["longitud sec"]

    return df

# Agrega las columnas de dinucleótidos al DataFrame
dataset = agregar_columnas_dinucleotidos(dataset)

#Creo el subconjunto de datos a usar para la predicción
X = dataset.iloc[:, 1:]

#Hago el escalado de los datos

#sc_X = StandardScaler()
X = sc_X.transform(X)

# Realiza la predicción
y_pred = modelo.predict(X)

print(y_pred[0])

if y_pred[0]==0:
  print('la secuencia ingresada tiene pocas probabilidades de ser causante de la enfermedad en cuestión')

else:
  print('la secuencia ingresada tiene altas probabilidades de ser causante de la enfermedad en cuestión')

#secuencia que debería dar 1: CUGGGAGAAGGCUGUUUACUCU  (usar para probar, está verificado que da 1)
#secuencia que debería dar 0: CCUCCGUGUUACCUGUCCUCUAG (usar para probar, está verificado que da 0)